{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0504481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from astropy.utils.data import download_file\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import logging, sys\n",
    "import numpy as np\n",
    "import statistics\n",
    "import warnings\n",
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import shutil\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "\n",
    "#Author: Angelica Psaridi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f05dd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.disable(sys.maxsize)\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "logging.disable(sys.maxsize)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "68cf52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_base = \"/Users/angelicapsaridi/Documents/Geneva/Recommissioning/Data/\"\n",
    "path =  \"/Users/angelicapsaridi/Documents/Geneva/Recommissioning/Tables/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "192c09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = []\n",
    "date = []\n",
    "date_eve = []\n",
    "date_mor = []\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(data_dir_base)\n",
    "\n",
    "for folder in glob.glob('2022*'):\n",
    "    date_list.append(folder)\n",
    "    date.append(folder)\n",
    "    date_eve.append(folder)\n",
    "    date_mor.append(folder)\n",
    "\n",
    "\n",
    "date_list.sort()\n",
    "date_eve.sort()\n",
    "date_mor.sort()\n",
    "date.sort()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8c7897d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_eve1 = []                    \n",
    "bias_all_eve = []\n",
    "bias_mor1 = []                    \n",
    "bias_all_mor = []\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(date_list)):\n",
    "    os.chdir(data_dir_base+date_list[i])\n",
    "    bias_all_eve.append([])\n",
    "    bias_all_mor.append([])\n",
    "    for frame in glob.glob(\"ECAM.*.fits\"):\n",
    "        hdul = fits.open(frame)\n",
    "        hdr = hdul[0].header \n",
    "        if hdr['HIERARCH OGE OBS TYPE'] == \"BIAS\":\n",
    "            if hdr['HIERARCH OGE DET OUT RNAME'] == \"ALL\":\n",
    "                hour = hdr['HIERARCH OGE OBS HOURSTU'][0:2]\n",
    "                if hour==\"19\" or hour==\"20\" or hour==\"21\" or hour==\"22\" or hour==\"23\" or hour==\"00\" or hour==\"01\" or hour==\"02\":\n",
    "                    bias_all_eve[-1].append(hdr['ARCFILE'])\n",
    "                elif hour==\"06\" or hour==\"07\" or hour==\"08\" or hour==\"09\" or hour==\"10\" or hour==\"11\" or hour==\"13\" or hour==\"13\":\n",
    "                    bias_all_mor[-1].append(hdr['ARCFILE'])\n",
    "\n",
    "\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4afbbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_eve = []                    \n",
    "bias_mor = []  \n",
    "\n",
    "\n",
    "for i in range(len(date_list)):\n",
    "    if (len(bias_all_eve[i])<=3):\n",
    "        date_eve.remove(date_list[i]) \n",
    "    else:\n",
    "        bias_eve1.append(bias_all_eve[i])\n",
    "        \n",
    "for i in range(len(date_list)):\n",
    "    if (len(bias_all_mor[i])<=3):\n",
    "        date_mor.remove(date_list[i]) \n",
    "    else:\n",
    "        bias_mor1.append(bias_all_mor[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7d16f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(date_eve)):\n",
    "    if (len(bias_eve1[i])>=5):\n",
    "        bias_eve.append(bias_eve1[i][0:5])\n",
    "    else:\n",
    "        bias_eve.append(bias_eve1[i])\n",
    "\n",
    "\n",
    "for i in range(len(date_mor)):\n",
    "    if (len(bias_mor1[i])>=5):\n",
    "        bias_mor.append(bias_mor1[i][0:5])\n",
    "    else:\n",
    "        bias_mor.append(bias_mor1[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "70159518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-16 ['ECAM.2022-02-16T23:24:11.000.fits', 'ECAM.2022-02-16T23:24:22.000.fits', 'ECAM.2022-02-16T23:24:00.000.fits', 'ECAM.2022-02-16T23:23:49.000.fits', 'ECAM.2022-02-16T23:23:38.000.fits']\n",
      "2022-05-15 ['ECAM.2022-05-15T21:51:27.000.fits', 'ECAM.2022-05-15T21:53:06.000.fits', 'ECAM.2022-05-15T21:52:00.000.fits', 'ECAM.2022-05-15T21:51:38.000.fits', 'ECAM.2022-05-15T21:52:55.000.fits']\n",
      "2022-06-01 ['ECAM.2022-06-02T01:32:16.000.fits', 'ECAM.2022-06-02T01:34:07.000.fits', 'ECAM.2022-06-01T21:40:11.000.fits', 'ECAM.2022-06-02T01:33:56.000.fits', 'ECAM.2022-06-02T01:35:13.000.fits']\n",
      "2022-07-11 ['ECAM.2022-07-11T22:26:30.000.fits', 'ECAM.2022-07-11T22:25:57.000.fits', 'ECAM.2022-07-11T22:26:19.000.fits', 'ECAM.2022-07-11T22:26:41.000.fits', 'ECAM.2022-07-11T22:26:08.000.fits']\n",
      "2022-09-04 ['ECAM.2022-09-04T21:25:45.000.fits', 'ECAM.2022-09-04T21:25:34.000.fits', 'ECAM.2022-09-04T21:25:01.000.fits', 'ECAM.2022-09-04T21:25:23.000.fits', 'ECAM.2022-09-04T21:26:08.000.fits']\n",
      "2022-09-06 ['ECAM.2022-09-06T20:57:13.000.fits', 'ECAM.2022-09-06T20:55:55.000.fits', 'ECAM.2022-09-06T20:55:43.000.fits', 'ECAM.2022-09-06T20:56:06.000.fits', 'ECAM.2022-09-06T20:57:02.000.fits']\n",
      "2022-09-18 ['ECAM.2022-09-18T23:11:29.000.fits', 'ECAM.2022-09-18T23:12:20.000.fits', 'ECAM.2022-09-18T23:12:56.000.fits', 'ECAM.2022-09-18T23:13:23.000.fits', 'ECAM.2022-09-18T23:13:48.000.fits']\n",
      "2022-10-03 ['ECAM.2022-10-03T21:54:30.000.fits', 'ECAM.2022-10-03T21:53:34.000.fits', 'ECAM.2022-10-03T21:54:20.000.fits', 'ECAM.2022-10-03T21:53:45.000.fits', 'ECAM.2022-10-03T21:54:08.000.fits']\n",
      "2022-10-14 ['ECAM.2022-10-14T21:59:27.000.fits', 'ECAM.2022-10-14T22:00:11.000.fits', 'ECAM.2022-10-14T21:58:48.000.fits', 'ECAM.2022-10-14T22:00:00.000.fits', 'ECAM.2022-10-14T21:59:15.000.fits']\n",
      "2022-11-07 ['ECAM.2022-11-07T22:46:43.000.fits', 'ECAM.2022-11-07T22:45:59.000.fits', 'ECAM.2022-11-07T22:46:54.000.fits', 'ECAM.2022-11-07T22:46:10.000.fits', 'ECAM.2022-11-07T22:47:27.000.fits']\n",
      "2022-11-12 ['ECAM.2022-11-12T22:58:22.000.fits', 'ECAM.2022-11-12T22:57:38.000.fits', 'ECAM.2022-11-12T22:58:00.000.fits', 'ECAM.2022-11-12T22:57:16.000.fits', 'ECAM.2022-11-12T22:58:33.000.fits']\n",
      "2022-11-26 ['ECAM.2022-11-27T00:16:41.000.fits', 'ECAM.2022-11-27T00:16:30.000.fits', 'ECAM.2022-11-27T00:17:25.000.fits', 'ECAM.2022-11-27T00:16:19.000.fits', 'ECAM.2022-11-27T00:15:56.000.fits']\n",
      "2022-11-27 ['ECAM.2022-11-27T22:15:11.000.fits', 'ECAM.2022-11-27T22:16:17.000.fits', 'ECAM.2022-11-27T22:15:44.000.fits', 'ECAM.2022-11-27T22:15:33.000.fits', 'ECAM.2022-11-27T22:15:00.000.fits']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(date_eve)):\n",
    "    print(date_eve[i],bias_eve[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b149c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analysis_bias(a):\n",
    "    return np.mean(a),np.std(a)\n",
    "\n",
    "def filter_bias(a,mean,std,sigmas):\n",
    "    distance_from_mean = abs(a - mean)\n",
    "    not_outlier = distance_from_mean < sigmas * std\n",
    "    no_outliers = a[not_outlier]\n",
    "    \n",
    "    return no_outliers\n",
    "\n",
    "def convert_1D(a):\n",
    "    a_1D=[]\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a[i])):\n",
    "            a_1D.append(a[i][j])\n",
    "            \n",
    "    return a_1D\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0c47896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-01\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-07-11\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-18\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-26\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-01\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-07-11\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-18\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-26\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-01\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-07-11\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-18\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-26\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-01\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-07-11\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-18\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-26\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "#Evening\n",
    "\n",
    "bias_LR=[]\n",
    "mean_bias_LR=[]\n",
    "std_bias_LR=[]\n",
    "outliers_LR=[]\n",
    "filtered_bias_LR=[]\n",
    "mean_bias_LR_night_eve=[]\n",
    "mean_std_LR_night_eve=[]\n",
    "temp=[]\n",
    "mean_temp_eve=[]\n",
    "rnoise_LR=[]\n",
    "mean_rnoise_LR_eve=[]\n",
    "std_rnoise_LR_eve=[]\n",
    "mean_rnoise_LR_eve_night=[]\n",
    "std_rnoise_LR_eve_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_eve)):\n",
    "    print('Date analyzed now:',date_eve[i])\n",
    "    os.chdir(data_dir_base+date_eve[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_LR.append([])\n",
    "    std_bias_LR.append([])\n",
    "    outliers_LR.append([])\n",
    "    filtered_bias_LR.append([])\n",
    "    temp.append([])\n",
    "    rnoise_LR.append([])\n",
    "    bias_LR.append([])\n",
    "    for k in range(len(bias_eve[i])):\n",
    "        print(int((k+1)/len(bias_eve[i])*100),'%')\n",
    "        LR = fits.open(bias_eve[i][k])\n",
    "        temp[-1].append(LR[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        LR[0].data = LR[0].data[101:2156,2149:4196]\n",
    "        bias_data = LR[0].data\n",
    "        bias_LR[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_LR[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_LR[-1].append(mean_filtered)\n",
    "        std_bias_LR[-1].append(std_filtered)\n",
    "    mean_bias_LR_night_eve.append(np.mean(mean_bias_LR[-1]))        \n",
    "    mean_std_LR_night_eve.append(np.mean(std_bias_LR[-1]))  \n",
    "    mean_temp_eve.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_LR[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_LR[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_LR[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_LR[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_LR[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_LR_eve.append(np.mean(rnoise_LR[-1]))     \n",
    "    std_rnoise_LR_eve.append(np.std(rnoise_LR[-1])) \n",
    "\n",
    "\n",
    "bias_LL=[]\n",
    "mean_bias_LL=[]\n",
    "std_bias_LL=[]\n",
    "outliers_LL=[]\n",
    "filtered_bias_LL=[]\n",
    "mean_bias_LL_night_eve=[]\n",
    "mean_std_LL_night_eve=[]\n",
    "temp=[]\n",
    "mean_temp_eve=[]\n",
    "rnoise_LL=[]\n",
    "mean_rnoise_LL_eve=[]\n",
    "std_rnoise_LL_eve=[]\n",
    "mean_rnoise_LL_eve_night=[]\n",
    "std_rnoise_LL_eve_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_eve)):\n",
    "    print('Date analyzed now:',date_eve[i])\n",
    "    os.chdir(data_dir_base+date_eve[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_LL.append([])\n",
    "    std_bias_LL.append([])\n",
    "    outliers_LL.append([])\n",
    "    filtered_bias_LL.append([])\n",
    "    temp.append([])\n",
    "    rnoise_LL.append([])\n",
    "    bias_LL.append([])\n",
    "    for k in range(len(bias_eve[i])):\n",
    "        print(int((k+1)/len(bias_eve[i])*100),'%')\n",
    "        LL = fits.open(bias_eve[i][k])\n",
    "        temp[-1].append(LL[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        LL[0].data = LL[0].data[101:2156,101:2148]\n",
    "        bias_data = LL[0].data\n",
    "        bias_LL[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_LL[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_LL[-1].append(mean_filtered)\n",
    "        std_bias_LL[-1].append(std_filtered)\n",
    "    mean_bias_LL_night_eve.append(np.mean(mean_bias_LL[-1]))        \n",
    "    mean_std_LL_night_eve.append(np.mean(std_bias_LL[-1]))  \n",
    "    mean_temp_eve.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_LL[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_LL[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_LL[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_LL[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_LL[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_LL_eve.append(np.mean(rnoise_LL[-1]))     \n",
    "    std_rnoise_LL_eve.append(np.std(rnoise_LL[-1])) \n",
    "\n",
    "\n",
    "\n",
    "bias_UL=[]\n",
    "mean_bias_UL=[]\n",
    "std_bias_UL=[]\n",
    "outliers_UL=[]\n",
    "filtered_bias_UL=[]\n",
    "mean_bias_UL_night_eve=[]\n",
    "mean_std_UL_night_eve=[]\n",
    "temp=[]\n",
    "mean_temp_eve=[]\n",
    "rnoise_UL=[]\n",
    "mean_rnoise_UL_eve=[]\n",
    "std_rnoise_UL_eve=[]\n",
    "mean_rnoise_UL_eve_night=[]\n",
    "std_rnoise_UL_eve_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_eve)):\n",
    "    print('Date analyzed now:',date_eve[i])\n",
    "    os.chdir(data_dir_base+date_eve[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_UL.append([])\n",
    "    std_bias_UL.append([])\n",
    "    outliers_UL.append([])\n",
    "    filtered_bias_UL.append([])\n",
    "    temp.append([])\n",
    "    rnoise_UL.append([])\n",
    "    bias_UL.append([])\n",
    "    for k in range(len(bias_eve[i])):\n",
    "        print(int((k+1)/len(bias_eve[i])*100),'%')\n",
    "        UL = fits.open(bias_eve[i][k])\n",
    "        temp[-1].append(UL[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        UL[0].data = UL[0].data[2157:4212,101:2148]\n",
    "        bias_data = UL[0].data\n",
    "        bias_UL[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_UL[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_UL[-1].append(mean_filtered)\n",
    "        std_bias_UL[-1].append(std_filtered)\n",
    "    mean_bias_UL_night_eve.append(np.mean(mean_bias_UL[-1]))        \n",
    "    mean_std_UL_night_eve.append(np.mean(std_bias_UL[-1]))  \n",
    "    mean_temp_eve.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_UL[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_UL[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_UL[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_UL[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_UL[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_UL_eve.append(np.mean(rnoise_UL[-1]))     \n",
    "    std_rnoise_UL_eve.append(np.std(rnoise_UL[-1])) \n",
    "\n",
    "bias_UR=[]\n",
    "mean_bias_UR=[]\n",
    "std_bias_UR=[]\n",
    "outliers_UR=[]\n",
    "filtered_bias_UR=[]\n",
    "mean_bias_UR_night_eve=[]\n",
    "mean_std_UR_night_eve=[]\n",
    "temp=[]\n",
    "mean_temp_eve=[]\n",
    "rnoise_UR=[]\n",
    "mean_rnoise_UR_eve=[]\n",
    "std_rnoise_UR_eve=[]\n",
    "mean_rnoise_UR_eve_night=[]\n",
    "std_rnoise_UR_eve_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_eve)):\n",
    "    print('Date analyzed now:',date_eve[i])\n",
    "    os.chdir(data_dir_base+date_eve[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_UR.append([])\n",
    "    std_bias_UR.append([])\n",
    "    outliers_UR.append([])\n",
    "    filtered_bias_UR.append([])\n",
    "    temp.append([])\n",
    "    rnoise_UR.append([])\n",
    "    bias_UR.append([])\n",
    "    for k in range(len(bias_eve[i])):\n",
    "        print(int((k+1)/len(bias_eve[i])*100),'%')\n",
    "        UR = fits.open(bias_eve[i][k])\n",
    "        temp[-1].append(UR[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        UR[0].data = UR[0].data[2157:4212,2149:4196]\n",
    "        bias_data = UR[0].data\n",
    "        bias_UR[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_UR[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_UR[-1].append(mean_filtered)\n",
    "        std_bias_UR[-1].append(std_filtered)\n",
    "    mean_bias_UR_night_eve.append(np.mean(mean_bias_UR[-1]))        \n",
    "    mean_std_UR_night_eve.append(np.mean(std_bias_UR[-1]))  \n",
    "    mean_temp_eve.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_UR[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_UR[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_UR[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_UR[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_UR[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_UR_eve.append(np.mean(rnoise_UR[-1]))     \n",
    "    std_rnoise_UR_eve.append(np.std(rnoise_UR[-1])) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f1cc301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-19\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-19\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-19\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-02-16\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-05-15\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-06-19\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-04\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-09-06\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-03\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-10-14\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-07\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-12\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Date analyzed now: 2022-11-27\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "#morning\n",
    "\n",
    "bias_LR=[]\n",
    "mean_bias_LR=[]\n",
    "std_bias_LR=[]\n",
    "outliers_LR=[]\n",
    "filtered_bias_LR=[]\n",
    "mean_bias_LR_night_mor=[]\n",
    "mean_std_LR_night_mor=[]\n",
    "temp=[]\n",
    "mean_temp_mor=[]\n",
    "rnoise_LR=[]\n",
    "mean_rnoise_LR_mor=[]\n",
    "std_rnoise_LR_mor=[]\n",
    "mean_rnoise_LR_mor_night=[]\n",
    "std_rnoise_LR_mor_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_mor)):\n",
    "    print('Date analyzed now:',date_mor[i])\n",
    "    os.chdir(data_dir_base+date_mor[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_LR.append([])\n",
    "    std_bias_LR.append([])\n",
    "    outliers_LR.append([])\n",
    "    filtered_bias_LR.append([])\n",
    "    temp.append([])\n",
    "    rnoise_LR.append([])\n",
    "    bias_LR.append([])\n",
    "    for k in range(len(bias_mor[i])):\n",
    "        print(int((k+1)/len(bias_mor[i])*100),'%')\n",
    "        LR = fits.open(bias_mor[i][k])\n",
    "        temp[-1].append(LR[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        LR[0].data = LR[0].data[101:2156,2149:4196]\n",
    "        bias_data = LR[0].data\n",
    "        bias_LR[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_LR[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_LR[-1].append(mean_filtered)\n",
    "        std_bias_LR[-1].append(std_filtered)\n",
    "    mean_bias_LR_night_mor.append(np.mean(mean_bias_LR[-1]))        \n",
    "    mean_std_LR_night_mor.append(np.mean(std_bias_LR[-1]))  \n",
    "    mean_temp_mor.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_LR[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_LR[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_LR[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_LR[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_LR[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_LR_mor.append(np.mean(rnoise_LR[-1]))     \n",
    "    std_rnoise_LR_mor.append(np.std(rnoise_LR[-1])) \n",
    "\n",
    "\n",
    "bias_LL=[]\n",
    "mean_bias_LL=[]\n",
    "std_bias_LL=[]\n",
    "outliers_LL=[]\n",
    "filtered_bias_LL=[]\n",
    "mean_bias_LL_night_mor=[]\n",
    "mean_std_LL_night_mor=[]\n",
    "temp=[]\n",
    "mean_temp_mor=[]\n",
    "rnoise_LL=[]\n",
    "mean_rnoise_LL_mor=[]\n",
    "std_rnoise_LL_mor=[]\n",
    "mean_rnoise_LL_mor_night=[]\n",
    "std_rnoise_LL_mor_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_mor)):\n",
    "    print('Date analyzed now:',date_mor[i])\n",
    "    os.chdir(data_dir_base+date_mor[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_LL.append([])\n",
    "    std_bias_LL.append([])\n",
    "    outliers_LL.append([])\n",
    "    filtered_bias_LL.append([])\n",
    "    temp.append([])\n",
    "    rnoise_LL.append([])\n",
    "    bias_LL.append([])\n",
    "    for k in range(len(bias_mor[i])):\n",
    "        print(int((k+1)/len(bias_mor[i])*100),'%')\n",
    "        LL = fits.open(bias_mor[i][k])\n",
    "        temp[-1].append(LL[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        LL[0].data = LL[0].data[101:2156,101:2148]\n",
    "        bias_data = LL[0].data\n",
    "        bias_LL[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_LL[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_LL[-1].append(mean_filtered)\n",
    "        std_bias_LL[-1].append(std_filtered)\n",
    "    mean_bias_LL_night_mor.append(np.mean(mean_bias_LL[-1]))        \n",
    "    mean_std_LL_night_mor.append(np.mean(std_bias_LL[-1]))  \n",
    "    mean_temp_mor.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_LL[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_LL[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_LL[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_LL[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_LL[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_LL_mor.append(np.mean(rnoise_LL[-1]))     \n",
    "    std_rnoise_LL_mor.append(np.std(rnoise_LL[-1])) \n",
    "\n",
    "\n",
    "\n",
    "bias_UL=[]\n",
    "mean_bias_UL=[]\n",
    "std_bias_UL=[]\n",
    "outliers_UL=[]\n",
    "filtered_bias_UL=[]\n",
    "mean_bias_UL_night_mor=[]\n",
    "mean_std_UL_night_mor=[]\n",
    "temp=[]\n",
    "mean_temp_mor=[]\n",
    "rnoise_UL=[]\n",
    "mean_rnoise_UL_mor=[]\n",
    "std_rnoise_UL_mor=[]\n",
    "mean_rnoise_UL_mor_night=[]\n",
    "std_rnoise_UL_mor_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_mor)):\n",
    "    print('Date analyzed now:',date_mor[i])\n",
    "    os.chdir(data_dir_base+date_mor[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_UL.append([])\n",
    "    std_bias_UL.append([])\n",
    "    outliers_UL.append([])\n",
    "    filtered_bias_UL.append([])\n",
    "    temp.append([])\n",
    "    rnoise_UL.append([])\n",
    "    bias_UL.append([])\n",
    "    for k in range(len(bias_mor[i])):\n",
    "        print(int((k+1)/len(bias_mor[i])*100),'%')\n",
    "        UL = fits.open(bias_mor[i][k])\n",
    "        temp[-1].append(UL[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        UL[0].data = UL[0].data[2157:4212,101:2148]\n",
    "        bias_data = UL[0].data\n",
    "        bias_UL[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_UL[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_UL[-1].append(mean_filtered)\n",
    "        std_bias_UL[-1].append(std_filtered)\n",
    "    mean_bias_UL_night_mor.append(np.mean(mean_bias_UL[-1]))        \n",
    "    mean_std_UL_night_mor.append(np.mean(std_bias_UL[-1]))  \n",
    "    mean_temp_mor.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_UL[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_UL[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_UL[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_UL[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_UL[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_UL_mor.append(np.mean(rnoise_UL[-1]))     \n",
    "    std_rnoise_UL_mor.append(np.std(rnoise_UL[-1])) \n",
    "\n",
    "bias_UR=[]\n",
    "mean_bias_UR=[]\n",
    "std_bias_UR=[]\n",
    "outliers_UR=[]\n",
    "filtered_bias_UR=[]\n",
    "mean_bias_UR_night_mor=[]\n",
    "mean_std_UR_night_mor=[]\n",
    "temp=[]\n",
    "mean_temp_mor=[]\n",
    "rnoise_UR=[]\n",
    "mean_rnoise_UR_mor=[]\n",
    "std_rnoise_UR_mor=[]\n",
    "mean_rnoise_UR_mor_night=[]\n",
    "std_rnoise_UR_mor_night=[]\n",
    "\n",
    "\n",
    "for i in range(len(date_mor)):\n",
    "    print('Date analyzed now:',date_mor[i])\n",
    "    os.chdir(data_dir_base+date_mor[i])\n",
    "\n",
    "#Lower right quadrant\n",
    "    mean_bias_UR.append([])\n",
    "    std_bias_UR.append([])\n",
    "    outliers_UR.append([])\n",
    "    filtered_bias_UR.append([])\n",
    "    temp.append([])\n",
    "    rnoise_UR.append([])\n",
    "    bias_UR.append([])\n",
    "    for k in range(len(bias_mor[i])):\n",
    "        print(int((k+1)/len(bias_mor[i])*100),'%')\n",
    "        UR = fits.open(bias_mor[i][k])\n",
    "        temp[-1].append(UR[0].header['HIERARCH OGE AMBI TEMP'])\n",
    "        UR[0].data = UR[0].data[2157:4212,2149:4196]\n",
    "        bias_data = UR[0].data\n",
    "        bias_UR[-1].append(bias_data)\n",
    "        mean,std=analysis_bias(bias_data)\n",
    "        bias_filtered = filter_bias(bias_data,mean,std,5.)  \n",
    "        filtered_bias_UR[-1].append(bias_filtered)\n",
    "        mean_filtered,std_filtered=analysis_bias(bias_filtered)\n",
    "        mean_bias_UR[-1].append(mean_filtered)\n",
    "        std_bias_UR[-1].append(std_filtered)\n",
    "    mean_bias_UR_night_mor.append(np.mean(mean_bias_UR[-1]))        \n",
    "    mean_std_UR_night_mor.append(np.mean(std_bias_UR[-1]))  \n",
    "    mean_temp_mor.append(np.mean(temp[-1]))\n",
    "    for j in range(len(bias_UR[-1])):\n",
    "        os.chdir(data_dir_base+date[i])\n",
    "        print(int((j+1)/len(bias_UR[-1])*100),'%')\n",
    "        for k in range(j+1):\n",
    "                if j!=k:\n",
    "                    a = np.array(bias_UR[-1][j],dtype=np.int16)\n",
    "                    b = np.array(bias_UR[-1][k],dtype=np.int16)\n",
    "                    diff_bias = np.abs(np.subtract(a,b))\n",
    "                    mean,std=analysis_bias(diff_bias)\n",
    "                    diff_bias_filtered = filter_bias(diff_bias,mean,std,5.)\n",
    "                    rnoise_UR[-1].append(np.std(diff_bias_filtered)/math.sqrt(2.))\n",
    "                \n",
    "    mean_rnoise_UR_mor.append(np.mean(rnoise_UR[-1]))     \n",
    "    std_rnoise_UR_mor.append(np.std(rnoise_UR[-1])) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dca048f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'Readout_Noise_mor.csv', 'w+') as file:\n",
    "        writer = csv.writer(file)\n",
    "        data = ['Night','UL','UR','LL','LR','Temp']\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "\n",
    "with open(path+'Mean_Bias_mor.csv', 'w+') as file:\n",
    "        writer = csv.writer(file)\n",
    "        data = ['Night','UL','UR','LL','LR','Temp']\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8c9ca27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'Readout_Noise_mor.csv', 'a+') as file:\n",
    "    for i in range(len(date_mor)):\n",
    "        if (len(bias_mor[i])>=3):\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],round(mean_rnoise_UL_mor[i],3),round(mean_rnoise_UR_mor[i],3),round(mean_rnoise_LL_mor[i],3),round(mean_rnoise_LR_mor[i],3),round(mean_temp_mor[i],2)]\n",
    "            writer.writerow(data)\n",
    "        else:\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            writer.writerow(data)\n",
    "\n",
    "\n",
    "with open(path+'Mean_Bias_mor.csv', 'a+') as file:\n",
    "    for i in range(len(date_mor)):\n",
    "        if (len(bias_mor[i])>=3):\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],round(mean_bias_UL_night_mor[i],3),round(mean_bias_UR_night_mor[i],3),round(mean_bias_LL_night_mor[i],3),round(mean_bias_LR_night_mor[i],3),round(mean_temp_mor[i],2)]\n",
    "            writer.writerow(data)\n",
    "        else:\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            writer.writerow(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e6c07d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'Readout_Noise_eve.csv', 'w+') as file:\n",
    "        writer = csv.writer(file)\n",
    "        data = ['Night','UL','UR','LL','LR','Temp']\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n",
    "\n",
    "with open(path+'Mean_Bias_eve.csv', 'w+') as file:\n",
    "        writer = csv.writer(file)\n",
    "        data = ['Night','UL','UR','LL','LR','Temp']\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "804d94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'Readout_Noise_eve.csv', 'a+') as file:\n",
    "    for i in range(len(date_eve)):\n",
    "        if (len(bias_eve[i])>=3):\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],round(mean_rnoise_UL_eve[i],3),round(mean_rnoise_UR_eve[i],3),round(mean_rnoise_LL_eve[i],3),round(mean_rnoise_LR_eve[i],3),round(mean_temp_eve[i],2)]\n",
    "            writer.writerow(data)\n",
    "        else:\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            writer.writerow(data)\n",
    "\n",
    "with open(path+'Mean_Bias_eve.csv', 'a+') as file:\n",
    "    for i in range(len(date_eve)):\n",
    "        if (len(bias_eve[i])>=3):\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],round(mean_bias_UL_night_eve[i],3),round(mean_bias_UR_night_eve[i],3),round(mean_bias_LL_night_eve[i],3),round(mean_bias_LR_night_eve[i],3),round(mean_temp_eve[i],2)]\n",
    "            writer.writerow(data)\n",
    "        else:\n",
    "            writer = csv.writer(file)\n",
    "            data = [date[i],np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            writer.writerow(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aac6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
